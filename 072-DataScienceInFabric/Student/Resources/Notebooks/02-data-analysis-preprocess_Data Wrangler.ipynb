{"cells":[{"cell_type":"markdown","source":["## Module 2: Perform data prep and cleansing using Apache Spark and Data Wrangler\n","\n","In this challenge we will prepare the dataset for the model training.\n","\n","Now that you have ingested and explored the data, you can transform the data. You can either run code in a notebook, or use the Data Wrangler to generate code for you.\n","\n","**Data Wrangler** is a tool used in notebooks. It offers an easy-to-use interface for exploring data. This tool shows data in a grid format, offers automatic summary statistics, built-in visualizations, and a library of common data-cleaning operations. Each operation can be done in just a few clicks. It shows the changes to the data right away and creates code in pandas or PySpark that can be saved back to the notebook for future use.\n","\n","\n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"22b6ce14-490c-4feb-a25e-ee52c88a6630"},{"cell_type":"markdown","source":["#### Part 1 Launching Data Wrangler\n","\n","To explore and transform any pandas Dataframes in your notebook, launch Data Wrangler directly from the notebook.\n","\n",">[!NOTE]\n",">Data Wrangler can not be opened while the notebook kernel is busy. The cell execution must complete prior to launching Data Wrangler.\n","\n","Reference: [Lauching Data Wrangler](https://learn.microsoft.com/en-us/fabric/data-science/data-wrangler#launching-data-wrangler)\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"29566045-0621-42a3-81be-0d0ec62d760c"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read a CSV into a Pandas DataFrame\n","\n","load_from_lakehouse=  \n","\n","df=\n"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"68ad6809-f71a-4e71-9ad4-af65ac2b2cf0"},{"cell_type":"markdown","source":["\n","### Part 2 Data cleaning trought Data Wrangler\n","\n","There are different preprocessing steps that is important for developing robust, efficient and reliable machine learning models.  \n","\n","&nbsp;\n"," 1. Removing unnecessary columns from a dataset before training a machine learning model is a best practice that enhances model performance, improves interpretability & reduces complexity.\n","&nbsp;\n"," 2.  Machine learning algorithms do not support missing values, dropping rows with missing values ensures compatibility with a wide range of algorithms without needing additional imputation strategies.\n","&nbsp;\n"," 3. Handling duplicate rows is an essential step in data preparation because it ensures data quality.\n","&nbsp;   \n"," 4. Machine learning algorithms operate on numerical data (integers, floats, etc.). If you feed them non-numeric data (e.g., strings), they won’t work. You must adjust some columns data types.\n"," &nbsp;\n","\n","\n","Reference: [Browsing and applying data-cleaning operations](https://learn.microsoft.com/en-us/fabric/data-science/data-wrangler#browsing-data-cleaning-operations)\n"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"c6f4e0b4-3db3-473f-af58-3cee6454c757"},{"cell_type":"code","source":["# Code generated by Data Wrangler for pandas DataFrame\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"3a247905-3524-475d-b01d-1a594ad7b6c1"},{"cell_type":"markdown","source":["## Feature Engineering\n","\n","In the feature engineering process, especially when dealing with categorical data, encoding is a crucial step. One of the simplest methods for converting categorical values into numerical values is using the **LabelEncoder**. Here’s how and why you would use LabelEncoder in the feature engineering process:\n","\n","\n","**Label encoding** is a process where categorical variables are converted into numerical labels. Each unique category value is assigned a unique integer. This method is useful for ordinal categorical data where the categories have a natural order."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4d1e9057-9dd4-4067-a11f-ae655ff53169"},{"cell_type":"markdown","source":["1. Checking if datatypes are numerical"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"0ea7c801-19fa-4a9f-973d-c618398e4638"},{"cell_type":"code","source":["# Input the code to check the datatypes"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"71033523-a290-486b-b45e-22f3fcb6a26a"},{"cell_type":"markdown","source":["2. Transforming categorical values. Run the following cell as it is to get started with the encoding process."],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"51b63b60-498d-4502-9bfa-f27bc1e53184"},{"cell_type":"code","source":["# Import the LabelEncoder class from the sklearn.preprocessing module.\n","# LabelEncoder is a tool provided by the scikit-learn library, a popular library in Python for machine learning, which is used to encode categorical labels into numerical values\"\n","# Creates an instance of the LabelEncoder class and assigns it to the variable lab.\n","\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","lab = LabelEncoder()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"0db68ba1-4a38-4c9e-935b-547dd959cdde"},{"cell_type":"markdown","source":["Code to transform the categorical values, please complete the code according to the steps. Ask bing chat for help if needed. "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"29102c1d-c938-43ff-aa8f-43e953c185db"},{"cell_type":"code","source":["# 1.Iniatialize a dataframe to be cleaned.\n","data_df1 = df_clean \n","# 2.Split object and non-object data types. You could use variables and the functions Include and exclude for that. \n","obj =\n","not_obj =\n","# 3.Encode categorical columns \n","for i in range(0, obj.shape[1]):\n","  obj.iloc[:,i] = lab.fit_transform(obj.iloc[:,i])\n","\n","# 4.Combine enconded and non-enconded data\n","df_new =\n","# 4.Display the first 10 rows to evaluate\n","head(df_new)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"29fc8ab5-21ab-4564-a6b0-94bba87ef247"},{"cell_type":"markdown","source":["#### Save processed data to a Delta Table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"52f09856-116f-4f11-aa8a-fa12f3f4d177"},{"cell_type":"markdown","source":["Refer to notebook 1 for more information about vorder and optimizedwrite"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7f66c1cb-4d2b-443f-9136-97d52157a8cb"},{"cell_type":"code","source":["spark.conf.set(\"sprk.sql.parquet.vorder.enabled\", \"true\") # Enable Verti-Parquet write\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\") # Enable automatic delta optimized write"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"86dd7ed8-8b4b-47a2-87a7-f443d8ae90ee"},{"cell_type":"markdown","source":["Refer to notebook 1 for more information on writing delta tables to the lakehouse."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70591db6-ec5d-43e8-8dc1-e30beb541913"},{"cell_type":"code","source":["# Saving the dataframe as a delta table, please complete the code on line 4. \n","table_name = \"heartfailure_processed\"\n","data_df_processed = spark.createDataFrame(df_new)\n","data_df_processed.\"please add your code here\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"9a2df2c7-b352-4578-85ff-6b64b2b725b4"},{"cell_type":"code","source":["%%sql\n","\n","select * from heartfailure_processed limit 100;"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"sparksql","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"sqlViewState":{"chartOptions":{"aggregationType":"count","binsNumber":10,"categoryFieldKeys":["9"],"chartType":"column","isStacked":false,"pivotFieldKey":"9","seriesFieldKeys":["8"],"wordFrequency":"-1"},"tableOptions":{}}},"id":"88b6c7b9-c13a-41af-882e-eec2d5b1a5a8"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"dependencies":{"lakehouse":{"default_lakehouse":"91f9e346-7d62-4063-bfd8-07035bb08131","known_lakehouses":[],"default_lakehouse_name":"Lakehouse","default_lakehouse_workspace_id":"a1efaa53-a101-4fb3-a1ba-7beb731708ad"}}},"nbformat":4,"nbformat_minor":5}